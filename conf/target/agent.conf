# target-agent.conf: agent which receives Oracle audit data

# Name the components on this agent
audit_agent.sources = avro_source
audit_agent.channels = mem_channel
audit_agent.sinks = elasticsearch

# Describe/configure the source
audit_agent.sources.avro_source.type = avro
audit_agent.sources.avro_source.channels = mem_channel
audit_agent.sources.avro_source.bind = itrac925.cern.ch
audit_agent.sources.avro_source.port = 4545

# Use a channel which buffers events in memory
audit_agent.channels.mem_channel.type = memory
audit_agent.channels.mem_channel.capacity = 1000
audit_agent.channels.mem_channel.transactionCapacity = 100

# Describe the HDFS sink
audit_agent.sinks.hdfs_sink.type = org.apache.flume.sink.kite.DatasetSink
audit_agent.sinks.hdfs_sink.channel = mem_channel
audit_agent.sinks.hdfs_sink.kite.dataset.uri = dataset:hdfs://itrac925.cern.ch:8020/tmp/flume-events/
audit_agent.sinks.hdfs_sink.kite.entityParser = ch.cern.db.audit.flume.sink.kite.parser.JSONtoAvroParser$Builder

# Describe the Elasticsearch sink
audit_agent.sinks.elasticsearch.channel = mem_channel
audit_agent.sinks.elasticsearch.type = com.frontier45.flume.sink.elasticsearch2.ElasticSearchSink
audit_agent.sinks.elasticsearch.batchSize = 100
audit_agent.sinks.elasticsearch.hostNames = ela1:9300
audit_agent.sinks.elasticsearch.indexName = aud1
audit_agent.sinks.elasticsearch.serializer = ch.cern.db.audit.flume.sink.elasticsearch.serializer.JSONtoElasticSearchEventSerializer
audit_agent.sinks.elasticsearch.clusterName = dbaud  