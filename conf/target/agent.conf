# target-agent.conf: agent which receives Oracle audit data

# Name the components on this agent
audit_agent.sources = avro_source
audit_agent.channels = mem_channel
audit_agent.sinks = elasticsearch

# Describe/configure the source
audit_agent.sources.avro_source.type = avro
audit_agent.sources.avro_source.channels = mem_channel
audit_agent.sources.avro_source.bind = db-log-gateway.cern.ch
audit_agent.sources.avro_source.port = 4545

# Use a channel which buffers events in memory
audit_agent.channels.mem_channel.type = memory
audit_agent.channels.mem_channel.capacity = 100000
audit_agent.channels.mem_channel.transactionCapacity = 100

# Describe the HDFS sink
audit_agent.sinks.hdfs_sink.type = org.apache.flume.sink.kite.DatasetSink
audit_agent.sinks.hdfs_sink.channel = mem_channel
audit_agent.sinks.hdfs_sink.kite.dataset.uri = dataset:hdfs://itrac925.cern.ch:8020/tmp/flume-events/
audit_agent.sinks.hdfs_sink.kite.entityParser = ch.cern.db.flume.sink.kite.parser.JSONtoAvroParser$Builder

# Describe the Elasticsearch sink
audit_agent.sinks.elasticsearch.channel = mem_channel
audit_agent.sinks.elasticsearch.type = com.frontier45.flume.sink.elasticsearch2.ElasticSearchSink
audit_agent.sinks.elasticsearch.batchSize = 100
audit_agent.sinks.elasticsearch.hostNames = itdb-es-dev.cern.ch:9200
audit_agent.sinks.elasticsearch.client = rest
audit_agent.sinks.elasticsearch.indexName = db-audit-logs
audit_agent.sinks.elasticsearch.serializer = ch.cern.db.flume.sink.elasticsearch.serializer.JSONtoElasticSearchEventSerializer
audit_agent.sinks.elasticsearch.clusterName = itdb_dev
